{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z2kMvAvRHg7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **BONUS LESSON: Some basic sentiment analysis**\n",
        "Here we will look at some basic sentiment analysis. This example will show some basic code suggested by ChatGPT and then we will see how we can tweak this. We will also then add a user interface.\n",
        "\n",
        "This is a very simple semantic analysis example (and if you were doing this for real you would want a more advance semantic analysis tool, wich we will cover another time). This is just showing the basic idea (and one way of doing it)."
      ],
      "metadata": {
        "id": "hEQigJiUHlE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will also cover installing packages and some if statements. Packages help us add more fucntionality to Python. Here we will install Gradio package from Hugging Face. We will use pip install to do this."
      ],
      "metadata": {
        "id": "pHwN4L_nICPG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nTdsustSHh0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio #this line installs the package."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgpkPvs__x0X",
        "outputId": "fc049b1a-f6b4-4791-81ba-1d7022e058ee"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.4 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets look at the code that ChatGPt suggested when asked if it could do sentiment analysis."
      ],
      "metadata": {
        "id": "hiR6HuPzBTNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I had a great time at the movie. The acting was superb and the plot was engaging.\"\n",
        "\n",
        "# Create a list of positive and negative words\n",
        "positive_words = [\"great\", \"superb\", \"engaging\"]\n",
        "negative_words = [\"bad\", \"terrible\", \"awful\"]\n",
        "\n",
        "# Initialize a variable to store the overall sentiment\n",
        "sentiment = 0\n",
        "\n",
        "# Split the text into words\n",
        "words = text.split()\n",
        "\n",
        "# Iterate through each word in the text\n",
        "for word in words:\n",
        "  # If the word is in the positive list, increment the sentiment\n",
        "  if word in positive_words:\n",
        "    sentiment += 1\n",
        "  # If the word is in the negative list, decrement the sentiment\n",
        "  elif word in negative_words:\n",
        "    sentiment -= 1\n",
        "\n",
        "# Print the overall sentiment\n",
        "if sentiment > 0:\n",
        "  print(\"Positive sentiment\")\n",
        "elif sentiment < 0:\n",
        "  print(\"Negative sentiment\")\n",
        "else:\n",
        "  print(\"Neutral sentiment\")"
      ],
      "metadata": {
        "id": "mVFw92oPHfxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK:** What do we think of it? What limitations are there of this code? What could we do to change/improve it? Feel free to copy it below and amend it to see if you could change anything."
      ],
      "metadata": {
        "id": "EeNL-H__Btw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A quick note on IF statements:** You may also notice in this code we use something called if statements. These say IF certain conditions are true do something. You can also state ELSE if statements. But we wont go into depth on that here."
      ],
      "metadata": {
        "id": "8DEsZqSyfzBm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But as a rough idea see below:"
      ],
      "metadata": {
        "id": "UI89OUTxgFxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales = 4 #we will set a random variable called sales to 10\n",
        "if sales > 5: #if sales are above 5\n",
        "  print(\"Nice one you are a sales machine!\") #print this\n",
        "else: # in all other instances print the below\n",
        "  print(\"Oh no you should go sell more. Maybe your ads are not great?!\")"
      ],
      "metadata": {
        "id": "Ao8k3Yf6B4bQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eb4d700-5410-4f78-b069-3097ce4d746c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh no you should go sell more. maybe your ads are not great?!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or another example using numbers in a list and checking if something is 'in' something."
      ],
      "metadata": {
        "id": "IjXdxQWhwYg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "items = [23,35,78,15] #create a list of items in this case numbers e.g. ID numbers\n",
        "if 24 in items: #if a certain number is in items\n",
        "  print(\"Yes it's here\") #print this\n",
        "else: #if its not in there, print the below.\n",
        "  print(\"No it's not in items\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdq7sOiowaLx",
        "outputId": "fa76c476-9e3f-4732-9c21-2d601ffd01c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No it's not in items\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the sentiment analysis above is using if statements to look if words in the text ar ein our list."
      ],
      "metadata": {
        "id": "SSmbadl3hBvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Okay back to our sentiment analysis.** So whilst there are a lot of limitations with the above code, it helps us as a very simple basic start point. One thing we may want to do is turn it into a function so we can make it more easy to re-use etc."
      ],
      "metadata": {
        "id": "LoRkXD2ndzum"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define our function for simple semantic analysis. It has a list of words it considers positive and negative. It then splits a sentence up and goes through each word checking if it is in the list. It then gives a score."
      ],
      "metadata": {
        "id": "-jcbAeyjJCf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "def sentiment_fun(text):\n",
        "  # Create a list of positive and negative words\n",
        "\n",
        "  positive_words = [\"great\", \"superb\", \"engaging\"]\n",
        "  negative_words = [\"bad\", \"terrible\", \"awful\"]\n",
        "  words = text.split() #crt a variable called words which is a split up of text\n",
        "  sentiment = 0\n",
        "  # Iterate through each word in the text\n",
        "  for word in words:\n",
        "  # If the word is in the positive list, increment the sentiment\n",
        "    if word in positive_words:\n",
        "      sentiment += 1\n",
        "  # If the word is in the negative list, decrement the sentiment\n",
        "    elif word in negative_words:\n",
        "      sentiment -= 1\n",
        "\n",
        "# Print the overall sentiment\n",
        "  if sentiment > 0:\n",
        "    print(\"Positive sentiment\")\n",
        "  elif sentiment < 0:\n",
        "    print(\"Negative sentiment\")\n",
        "  else:\n",
        "    print(\"Neutral sentiment\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "on9omzPHBVMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets now run it on a sentence we can give it and it should tell us if it is positive or negative."
      ],
      "metadata": {
        "id": "xCFig9lsJfuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_fun('I love superb plants amazing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU7OJpjACNqK",
        "outputId": "49115eb1-afcd-4316-8668-ebf5d1c264f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive sentiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now lets say we wanted to make an interface for this. One way of doing this is using Gradio from hugging face. the below code takes our function we have written and applies a User interface to it. This may make it easier for people to use etc.\n",
        "\n",
        "Please note in the code below we 'return' the sentiment result rather than print it out. This is so gradio can use this in the output. When you run the below it should come up with a user interface for you as well."
      ],
      "metadata": {
        "id": "pAiBPnR_JpxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "\n",
        "def sentiment_fun(text):\n",
        "  # Create a list of positive and negative words\n",
        "\n",
        "  positive_words = [\"great\", \"superb\", \"engaging\"]\n",
        "  negative_words = [\"bad\", \"terrible\", \"awful\"]\n",
        "  words = text.split()\n",
        "  sentiment = 0\n",
        "  # Iterate through each word in the text\n",
        "  for word in words:\n",
        "  # If the word is in the positive list, increment the sentiment\n",
        "    if word in positive_words:\n",
        "      sentiment += 1\n",
        "  # If the word is in the negative list, decrement the sentiment\n",
        "    elif word in negative_words:\n",
        "      sentiment -= 1\n",
        "\n",
        "# Print the overall sentiment\n",
        "  if sentiment > 0:\n",
        "    return(\"Positive sentiment\")\n",
        "  elif sentiment < 0:\n",
        "    return(\"Negative sentiment\")\n",
        "  else:\n",
        "    return(\"Neutral sentiment\")\n",
        "\n",
        "#Below we now create a user interface for this\n",
        "demo = gr.Blocks() #using Blocks form Gradio\n",
        "\n",
        "with demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "    # Sentiment Analysis (but very basic...)!\n",
        "    Type a sentence below to find its sentiment.\n",
        "    \"\"\"\n",
        "    )\n",
        "    input = gr.Textbox(placeholder=\"Type sentence here to check sentiment\") #creates input section\n",
        "    output = gr.Textbox(label=\"Sentiment result:\") #creates output\n",
        "\n",
        "    input.change(fn=sentiment_fun, inputs=input, outputs=output) #tells us what function to use on the input and uses input/output from above\n",
        "\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "XewbfHFGDATB",
        "outputId": "3134e922-bfa6-4102-8732-1c250e67b40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://01a740e008c1476422.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://01a740e008c1476422.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TASK**: Try and improve our sentiment analysis tool by amending the words it uses to judge the text. Could you add more positive words? More negative words? Could you do anything else?"
      ],
      "metadata": {
        "id": "XdDMQZiYGhMh"
      }
    }
  ]
}